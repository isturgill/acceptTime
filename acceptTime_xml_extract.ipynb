{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# acceptTime_xml_extract\n",
    "\n",
    "## Purpose\n",
    "This notebook documents the process of extracting date data from PLOS article XML files.\n",
    "\n",
    "## Workflow\n",
    "The workflow begins by updating a local directory of allofplos to reflect newly published articles since the last update. As of 11/26/2023, there were 347,607 total articles taking up around 38GB of storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External allofplos update command\n",
    "# !python -m allofplos.update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, my focus is on primary research articles published for the first time, so I'll filter out entries for corrected articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3641 corrected articles removed from final XML list.\n"
     ]
    }
   ],
   "source": [
    "# List all PLOS article XMLs in allofplos - points to local directory for allofplos module\n",
    "xml_list = os.listdir(\".venv/Lib/site-packages/allofplos/allofplos_xml/\")\n",
    "\n",
    "# Remove corrected articles\n",
    "xml_no_corr = []\n",
    "xml_before = len(xml_list)\n",
    "\n",
    "for xml in xml_list:\n",
    "    corrected = xml.find(\"correct\")\n",
    "    if corrected == -1:\n",
    "        xml_no_corr.append(xml)\n",
    "\n",
    "xml_after = len(xml_no_corr)\n",
    "\n",
    "print(f\"{xml_before - xml_after} corrected articles removed from final XML list.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the **xmltodict** module to read the XML files as more accessible Python dictionaries. Below are several functions to help us parse the resulting xmltodict dictionary objects, taking advantage of the relatively rigid structure of PLOS article XMLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "\n",
    "def readxml(xml_path):\n",
    "    \"\"\"\n",
    "    Reads XML files as Python dictionary objects.\n",
    "\n",
    "    Param xml_path: Local file path to XML file\n",
    "    Returns: Python dictionary (xmldict) object\n",
    "    \"\"\"\n",
    "\n",
    "    xml = open(xml_path, \"r\", encoding = \"utf-8\")\n",
    "\n",
    "    xml_content = xml.read()\n",
    "    xml_dict = xmltodict.parse(xml_content)\n",
    "    xml.close()\n",
    "    return(xml_dict)\n",
    "\n",
    "\n",
    "def get_date(branch):\n",
    "    \"\"\"\n",
    "    Retrieves and formats the date from a Python dictionary (xmltodict) object branch.\n",
    "    If \"day\" dictionary key is missing, defaults day value to 1.\n",
    "\n",
    "    Param branch: Branch of an xmltodict object that has date information\n",
    "    Returns: Formatted date\n",
    "    \"\"\"\n",
    "\n",
    "    if \"day\" in branch.keys():\n",
    "        out_date = branch[\"year\"] + \"-\" + branch[\"month\"] + \"-\" + branch[\"day\"]\n",
    "    else:\n",
    "        out_date = branch[\"year\"] + \"-\" + branch[\"month\"] + \"-\" \"1\"\n",
    "    return(out_date)\n",
    "\n",
    "\n",
    "def find_dates(xmldict):\n",
    "    \"\"\"\n",
    "    Finds and retrieves: received, accepted, and epub dates from a \n",
    "    Python dictionary (xmltodict) object.\n",
    "\n",
    "    Param xmldict: Python dictionary (xmltodict) object\n",
    "    Returns: List of dates in format [receive_date, accept_date, epub_date]\n",
    "    \"\"\"\n",
    "    \n",
    "    receive_date = \"\"\n",
    "    accept_date = \"\"\n",
    "    epub_date = \"\"\n",
    "\n",
    "    if \"history\" in xmldict[\"article\"][\"front\"][\"article-meta\"].keys():\n",
    "        date_branch = xmldict[\"article\"][\"front\"][\"article-meta\"][\"history\"][\"date\"]\n",
    "        has_keys = False\n",
    "\n",
    "        try: \n",
    "            if \"received\" in date_branch.values() or \"accepted\" in date_branch.values():\n",
    "                has_keys = True\n",
    "        except: \n",
    "            has_keys = False\n",
    "\n",
    "        if has_keys:\n",
    "            if date_branch[\"@date-type\"] == \"received\":\n",
    "                receive_date = get_date(date_branch)\n",
    "            elif date_branch[\"@date-type\"] == \"accepted\":\n",
    "                accept_date = get_date(date_branch)\n",
    "                \n",
    "\n",
    "        else: \n",
    "            for hist_entry in date_branch:\n",
    "                if hist_entry[\"@date-type\"] == \"received\":\n",
    "                    receive_date = get_date(hist_entry)\n",
    "\n",
    "                elif hist_entry[\"@date-type\"] == \"accepted\":\n",
    "                    accept_date = get_date(hist_entry)\n",
    "\n",
    "    if \"pub-date\" in xmldict[\"article\"][\"front\"][\"article-meta\"].keys():\n",
    "        for pub_entry in xmldict[\"article\"][\"front\"][\"article-meta\"][\"pub-date\"]:\n",
    "            if pub_entry[\"@pub-type\"] == \"epub\":\n",
    "                epub_date = get_date(pub_entry)\n",
    "                \n",
    "    return(receive_date, accept_date, epub_date)\n",
    "\n",
    "\n",
    "def get_doi(xmldict):\n",
    "    \"\"\"\n",
    "    Retrieves DOI for a Python dictionary (xmltodict) object.\n",
    "\n",
    "    Param xml: Python dictionary (xmltodict) object\n",
    "    Returns: DOI string\n",
    "    \"\"\"\n",
    "\n",
    "    doi = \"\"\n",
    "    id_branch = xmldict[\"article\"][\"front\"][\"article-meta\"][\"article-id\"]\n",
    "    has_keys = False\n",
    "    \n",
    "    try: \n",
    "        if len(id_branch.keys()) > 0:\n",
    "            has_keys = True\n",
    "    except: pass\n",
    "\n",
    "    if has_keys:\n",
    "        doi = id_branch[\"#text\"]\n",
    "    else:\n",
    "        for id in id_branch:\n",
    "            if id[\"@pub-id-type\"] == \"doi\":\n",
    "                doi = id[\"#text\"]\n",
    "\n",
    "    return(doi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we iterate through all of the PLOS articles in allofplos that are first-time publications of research articles (not corrections). This step has not been parallelized and takes about 3 hours to run sequentially through the more than 300,000 articles in allofplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize information lists\n",
    "received_dates = []\n",
    "accepted_dates = []\n",
    "epub_dates = []\n",
    "journals = []\n",
    "article_dois = []\n",
    "skipped_articles = 0\n",
    "\n",
    "# Iterate through all non-correction research articles\n",
    "# Also keeps a count of any skipped articles due to XML, formatting, or other errors (note: only 1 article skipped when run on 11/26/2023)\n",
    "for xml in xml_no_corr:\n",
    "    try: \n",
    "        xml_path = \".venv/Lib/site-packages/allofplos/allofplos_xml/\" + xml\n",
    "        xmldict = readxml(xml_path)\n",
    "\n",
    "        if xmldict[\"article\"][\"@article-type\"] == \"research-article\":\n",
    "            journal = xml.split(\".\")[1]\n",
    "            journals.append(journal)\n",
    "            xml_dates = find_dates(xmldict)\n",
    "            received_dates.append(xml_dates[0])\n",
    "            accepted_dates.append(xml_dates[1])\n",
    "            epub_dates.append(xml_dates[2])\n",
    "            article_dois.append(get_doi(xmldict))\n",
    "    \n",
    "    except: skipped_articles += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a pandas dataframe from the extracted information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(list(zip(received_dates, accepted_dates, epub_dates, journals, article_dois)),\n",
    "                  columns = [\"received_date\", \"accepted_date\", \"epub_date\", \"journal\", \"article_doi\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need a function to compute differences in time so that we can get the time from submission (received_date) to acceptance or publish date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import math\n",
    "\n",
    "def time_diff(date1, date2):\n",
    "    \"\"\"\n",
    "    Computes the difference between two dates in days.\n",
    "\n",
    "    Param date1: First date string in the \"YYYY-MM-DD\" format\n",
    "    Param date2: Second date string in the \"YYYY-MM-DD\" format\n",
    "    Returns: Difference in days between date2 and date2\n",
    "    \"\"\"\n",
    "    \n",
    "    diff = pd.NA\n",
    "    \n",
    "    if type(date1) == str and date1 != \"\" and type(date2) == str and date2 != \"\" :\n",
    "        date1_format = date1.split(\"-\")\n",
    "        date1_format = date(int(date1_format[0]), int(date1_format[1]), int(date1_format[2]))\n",
    "        date2_format = date2.split(\"-\")\n",
    "        date2_format = date(int(date2_format[0]), int(date2_format[1]), int(date2_format[2]))\n",
    "        diff = date2_format - date1_format\n",
    "        return(diff.days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the time differences and add those values to the pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(326737, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>received_date</th>\n",
       "      <th>accepted_date</th>\n",
       "      <th>epub_date</th>\n",
       "      <th>journal</th>\n",
       "      <th>article_doi</th>\n",
       "      <th>accept_time</th>\n",
       "      <th>receive_to_pub_time</th>\n",
       "      <th>accept_to_pub_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-6-1</td>\n",
       "      <td>2003-7-10</td>\n",
       "      <td>2003-10-13</td>\n",
       "      <td>pbio</td>\n",
       "      <td>10.1371/journal.pbio.0000001</td>\n",
       "      <td>39.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-5-19</td>\n",
       "      <td>2003-7-16</td>\n",
       "      <td>2003-11-17</td>\n",
       "      <td>pbio</td>\n",
       "      <td>10.1371/journal.pbio.0000002</td>\n",
       "      <td>58.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-6-12</td>\n",
       "      <td>2003-7-25</td>\n",
       "      <td>2003-8-18</td>\n",
       "      <td>pbio</td>\n",
       "      <td>10.1371/journal.pbio.0000005</td>\n",
       "      <td>43.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-6-3</td>\n",
       "      <td>2003-7-29</td>\n",
       "      <td>2003-8-18</td>\n",
       "      <td>pbio</td>\n",
       "      <td>10.1371/journal.pbio.0000006</td>\n",
       "      <td>56.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-6-20</td>\n",
       "      <td>2003-8-1</td>\n",
       "      <td>2003-10-13</td>\n",
       "      <td>pbio</td>\n",
       "      <td>10.1371/journal.pbio.0000010</td>\n",
       "      <td>42.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  received_date accepted_date   epub_date journal  \\\n",
       "0      2003-6-1     2003-7-10  2003-10-13    pbio   \n",
       "1     2003-5-19     2003-7-16  2003-11-17    pbio   \n",
       "2     2003-6-12     2003-7-25   2003-8-18    pbio   \n",
       "3      2003-6-3     2003-7-29   2003-8-18    pbio   \n",
       "4     2003-6-20      2003-8-1  2003-10-13    pbio   \n",
       "\n",
       "                    article_doi  accept_time  receive_to_pub_time  \\\n",
       "0  10.1371/journal.pbio.0000001         39.0                134.0   \n",
       "1  10.1371/journal.pbio.0000002         58.0                182.0   \n",
       "2  10.1371/journal.pbio.0000005         43.0                 67.0   \n",
       "3  10.1371/journal.pbio.0000006         56.0                 76.0   \n",
       "4  10.1371/journal.pbio.0000010         42.0                115.0   \n",
       "\n",
       "   accept_to_pub_time  \n",
       "0                95.0  \n",
       "1               124.0  \n",
       "2                24.0  \n",
       "3                20.0  \n",
       "4                73.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize lists\n",
    "accept_time = []\n",
    "receive_to_pub_time = []\n",
    "accept_to_pub_time = []\n",
    "\n",
    "# Iterate through each row of the dataframe\n",
    "for i in range(df.shape[0]):\n",
    "    t1 = time_diff(df.loc[i, \"received_date\"], df.loc[i, \"accepted_date\"])\n",
    "    accept_time.append(t1)\n",
    "\n",
    "    t2 = time_diff(df.loc[i, \"received_date\"], df.loc[i, \"epub_date\"])\n",
    "    receive_to_pub_time.append(t2)\n",
    "\n",
    "    t3 = time_diff(df.loc[i, \"accepted_date\"], df.loc[i, \"epub_date\"])\n",
    "    accept_to_pub_time.append(t3)\n",
    "\n",
    "# Add computed times to dataframe\n",
    "df[\"accept_time\"] = accept_time\n",
    "df[\"receive_to_pub_time\"] = receive_to_pub_time\n",
    "df[\"accept_to_pub_time\"] = accept_to_pub_time\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the processed data and then use it for downstream analyses in Python and/or R. One final note: there are a small number of negative values. These are due to nonsensical date values in some older XML documents. These values are not carried over into a filtered dataframe subset of recently published articles (e.g. last 180 days). There are also very low time to acceptance values like 0 days or 1 day (e.g. 10.1371/journal.pgen.1007429), but spot-checking shows that these are true values -- in this case, received May 17, 2018 and accepted May 18, 2018. These are likely rare special cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = f\"data/{date.today()}_plostime_data.txt\"\n",
    "df.to_csv(out_file, sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
